# Robust-Visual-Localization-for-Automotive-Applications

<img src=images/nexar_logo.jpeg width=135/>

![triplets](images/triplets.jpg)

Extensive experiments demonstrate that extra depth information helps networks to determine driving policies indeed. We hope it will become useful resources for the autonomous driving research community.

_Created by Nexar &reg;_

The full paper describing our work is available on arxiv: [paper](https://arxiv.org/abs/1905.0000)

## News!
___The full Visual Localization dataset will be published here soon. Stay tuned!___


## Contents
1. [Introduction](#introduction)
2. [Requirements](#requirements)
3. [Quick Start](#quick-start)
5. [Contributors](#contributors)
6. [Citation](#citation)
7. [License](#license)

## Introduction
This work is based on our [research paper](https://arxiv.org/abs/1905.0000), which appears in CVPR 2019. We propose a robust visual localization approach for automotive applications.

## Requirements

* Python 2.7
* Python Libraries: numpy, scipy
* ???

## Quick Start


## Contributors


## Citation
If you wish to use our dataset or code, please use the following bibtex for citation:

	@InProceedings{...,
	  author = {...},
	  title = {Accurate Visual Localization for Automotive Applications},
	  booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	  month = {June},
	  year = {2019}
	}

## License
Our code is released under Apache 2.0 License. The copyright of Nexar could be checked [here](https://getnexar.com/).
